# atom_agent.nodes.reflector Documentation

## Overall Flow
`src/atom_agent/nodes/reflector.py` implements the Reflection Node, which acts as the quality assurance layer of the agent. It reviews the work produced by the `executor` node against the defined acceptance criteria and decides whether to proceed, refine, or rollback.

The flow is:
1.  **Context Preparation**: Gathers evidence from multiple sources:
    -   **Test Results**: Reads `test_results.json` generated by the test suite.
    -   **Artifacts**: Summarizes files created in the `artifacts/` directory.
    -   **Programmatic Pre-checks**: Runs 3 machine-level checks (hardcoded strings, existence-only tests, dependency gaps) and injects results into the prompt.
    -   **Chat History**: Reviews the last 10 messages of the executor's conversation.
    -   **Dependencies**: Checks status of dependent steps.
2.  **LLM Evaluation**: Prompts `gemini-3-pro-preview` (via `get_llm("reflector")`) with a structured prompt containing the evidence and criteria.
3.  **Parsing**: Parses the LLM's JSON response, handling markdown fences and potential formatting errors robustly.
4.  **Action**:
    -   Persists the review to `report.json`.
    -   Updates the `step.status` in the implementation plan based on the decision (`accepted`, `refined`, `failed`).
    -   Returns the review in the state dictionary.

## Use Cases
-   **Verification**: Ensures that the code actually meets requirements before moving on.
-   **Self-Correction**: Detects failures (e.g., tests failing) and triggers a refine loop.
-   **Documentation**: Generates a structured report of *why* a step was considered successful or failed.

## Edge Cases
-   **Invalid JSON**: Contains fallback logic to handle cases where the LLM outputs malformed JSON (defaults to `refine` with an error message).
-   **Missing Artifacts**: Handles missing `test_results.json` or empty artifact directories gracefully.
-   **Scoring Caps**: Implements deterministic caps for systemic issues:
    -   **0.49 (FAIL)**: If the implementation is detected as hardcoded or mocked.
    -   **0.59 (REFINE)**: If tests are shallow (existence only) or dependencies are missing.
-   **Max Attempts**: While the router handles the loop limit, the reflector records the failure status.

## Method Documentation

### `_run_programmatic_prechecks(task_dir_rel, staging_paths, current_step) -> str`
Performs machine-level quality checks before the LLM evaluation.
-   **Hardcoded Check**: Detects long string literals in `impl.py` that suggest mocked output.
-   **Shallow Test Check**: Detects tests that only use `os.path.exists` without content assertions.
-   **Dependency Check**: Verifies that any used `committed/artifacts` correctly correspond to declared dependencies.

### `reflector_node(state: AgentState) -> Dict[str, Any]`
The primary node function.

-   **Logic**:
    -   Resolves paths using `Workspace`.
    -   Constructs evidence strings (test output, artifact snippets, logs).
    -   Invokes LLM with `REFLECTOR_USER_PROMPT`.
    -   Parses/Validates JSON output.
    -   Saves `report.json`.
    -   Updates state (`reflector_review`, `progress_reports`, `implementation_plan`).
-   **Returns**: Updated state dictionary.
